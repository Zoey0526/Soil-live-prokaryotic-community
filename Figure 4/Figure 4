#Figure 4A distance-dacy
setwd("D:/")
  data <- read.csv('Tsimilarity.csv',header = T)
  install.packages("ggplot2")
  library(geosphere)
  library(ggpubr)
  library(ggplot2)
  library(ggpmisc)
  install
  site_dis <- geosphere::distm(sample[c('longitude', 'laititude')])
  data$group <- factor(data$group,levels = c("T","D","S","P","R"))
  scale_color_manual(values = c("#0073c2","#fa8072","#D5544D","#7aa6dc","#efc000","#ffff00","#27ae60","#317e00"))
  p1 <- ggplot(data, aes( x = site_dis/1000, y =  comm_sim, color = group)) +
    geom_point( aes( color = group),size=1.5,alpha=0.5)+ 
    scale_color_manual(values = c("#80B1D3","#FB8072" ,"#BEBADA","#FFCC00","#8DD3C7"))+
    labs(x="Distance (km)",y="Bray-Curtis Similarity")+
    geom_smooth(method = 'lm', formula = y ~ x, se = F,size=1.5) +
    stat_poly_eq(aes(label=paste(..rr.label..,..p.value.label..,sep = "~~~~")),formula = y~x,parse=T,size=2.5)+
    theme_bw()+theme(panel.grid.major= element_blank())
  p2 <- p1+labs(color = "Treat")
  p2
  library(dplyr)
  install.packages("ggpmisc")
  library(ggpmisc)
  library(ggpubr)
  library(gridExtra)
  data <- read.csv('Tsimilarity.csv',  row.names = 1, check.names = FALSE)
  fit <- lm(comm_sim~site_dis, data = comm_dis) 

##Figure 4B MST
setwd("E:/DY/MST/Total")
library(NST)
comm_S<-read.csv("OTU_rare.csv",header=T,row.names=1)
group_S <-read.csv("group_MST.csv", header=F,row.names = 1)
comm_S<-t(comm_S)
set.seed(123)
tnst <- tNST(comm = comm_S, group = group_S, dist.method = 'jaccard', null.model = 'PF', 
             rand = 1000, nworker = 50)
names(tnst)
tnst$index.pair
tnst$index.grp
nst_group <- tnst$index.pair.grp
nst_group
write.csv(nst_group,'MST.csv')
setwd("D:/")
install.packages("Hmisc")
library(Hmisc)
library(ggplot2)
library(ggpubr)
data = read.csv("nst.csv", header=T)
group = read.csv("group.csv", header=F,row.names = 1)
col=c("#80b1d3","#fb8072","#BEBADA", "#FFCC00","#8DD3C7")
col=c("#fb8072","#FFFFB3","#8DD3C7", "#BEBADA","#80b1d3")
my_comparisons <- list(c("T", "D"),  c("T", "R"),
                       c("D", "S"), c("D", "P"), c("D", "R"), c("S", "P")
                       , c("S", "R"), c("P", "R"))
p = ggplot(data,aes(fill = group,x=factor(group,level=c("T","D","S","P","R")), y=MST.ij.ruzicka))+
  geom_violin(position = position_dodge(width = 0.1), scale = 'width')+  
  geom_violin(position = position_dodge(width = 0.1), scale = 'width')+  
  geom_boxplot(alpha=1,outlier.size=0, size=0.3, width=0.3,fill="white")+
  scale_fill_manual(values = col)+
  labs(x="Treat", y="Modified Stochasticity Ratio(MST)", color=group)+
  scale_x_discrete(limits=c("T","D","S","P","R")+
  ylim(0, 1))
mytheme = theme_classic() + theme(axis.text.x = element_text(size = 12),axis.text.y = element_text(size = 12))+
  theme(axis.title.y= element_text(size=15))+theme(axis.title.x = element_text(size = 15))+
  theme(legend.title=element_text(size=10),legend.text=element_text(size=10))
p2=p+mytheme
p2 
ggsave("MST_box.pdf", p4, width = 150, height = 180,units = "mm")
p4 = ggplot(data,aes(group,x=factor(group,level=c("T","D","S","P","R")), y=MST.ij.ruzicka))+###abundanceï¼š y=species
  stat_boxplot(geom="errorbar",width=0.15)+
  scale_fill_manual(values = col)+
  geom_boxplot(alpha=0.7,aes(fill=group))+
  #geom_line(aes(group=group) ,colour="#9C9C9C",lwd=0.2)+
  #geom_point(size = 0.5)+
  scale_y_continuous(name="Modified Stochasticity Ratio(MST)")+
  scale_x_discrete(name="Treat")+
  theme_bw()+
  theme(legend.position='none')+
  theme(panel.background = element_rect(fill = "white", colour = "black"),
        panel.grid = element_blank(),
        panel.border = element_blank(),
        text = element_text(colour="black",size=12),
        axis.title = element_text(colour="black",face="bold"),
        axis.text=element_text(colour="black",size=12),
        axis.title.x = element_blank(),
        axis.title.y = element_text(colour="black", size = 12))+
  xlab("Treat")+ylab("Modified Stochasticity Ratio(MST) ")+coord_cartesian(ylim = c(0,1))

## Figure 4C iCAPM
m(list=ls())
  t0=Sys.time() # to calculate time cost
  # 3 # load R packages and data
  library(iCAMP)
  library(ape)
  # 1 # set folder paths and file names, please change according to the folder paths and file names in your computer.
  # the folder saving the input files
  wd="F:/R"
  # the OTU table file (Tab delimited txt file)
  comm<-t(read.csv("OTU_rare.csv",header=T,row.names=1,check.names = F))
  # the phylogenetic tree file
  tree<-read.tree("root_tree.nwk")
  # the environmental varialbes
  env<-read.csv("ENV11.csv", header=TRUE, row.names=1)
  # if you do not have env file or the env may not represent niche, skip step 7 and 8, but check the alternative way to determine binning setting, e.g. bin.size.limit.
  # the folder to save the output. please change to a new folder even if you are just testing the example data.
  save.wd="F:/R"
  if(!dir.exists(save.wd)){dir.create(save.wd)}
  # 2 # key parameter setting
  prefix="Test"  # prefix of the output file names. usually use a project ID.
  rand.time=100  # randomization time, 1000 is usually enough. For example test, you may set as 100 or less to save time.
  nworker=8 # nworker is thread number for parallel computing, which depends on the CPU core number of your computer.
  memory.G=11 # to set the memory size as you need (but should be less than the available space in your hard disk), so that calculation of large tree will not be limited by physical memory. unit is Gb.
  setwd(wd)
  # 4 # match sample IDs in OTU table and treatment information table
  sampid.check=match.name(rn.list=list(comm=comm,env=env)) 
  comm=sampid.check$comm
  comm=comm[,colSums(comm)>0,drop=FALSE] 
  env=sampid.check$env 
  # 5 # match OTU IDs in OTU table and tree file
  spid.check=match.name(cn.list=list(comm=comm),tree.list=list(tree=tree))
  comm=spid.check$comm
  tree=spid.check$tree
  # 6 # calculate pairwise phylogenetic distance matrix.
  setwd(save.wd)
  if(!file.exists("pd.desc")) 
  {
    pd.big=iCAMP::pdist.big(tree = tree, wd=save.wd, nworker = nworker, memory.G = memory.G)
  }else{
    # if you already calculated the phylogenetic distance matrix in a previous run
    pd.big=list()
    pd.big$tip.label=read.csv(paste0(save.wd,"/pd.taxon.name.csv"),row.names = 1,stringsAsFactors = FALSE)[,1]
    pd.big$pd.wd=save.wd
    pd.big$pd.file="pd.desc"
    pd.big$pd.name.file="pd.taxon.name.csv"
  }
  # 7 # assess niche preference difference between species
  # env is required for this step.
  setwd(save.wd)
  niche.dif=iCAMP::dniche(env = env,comm = comm,method = "niche.value",
                          nworker = nworker,out.dist=FALSE,bigmemo=TRUE,
                          nd.wd=save.wd)
  # 8 # within-bin phylogenetic signal assessment.
  # For real data, you may try several different settings of binning, and choose the one leading to the best within-bin phylogenetic signal.
  # env is required for this step.
  # 8.1 # try phylogenetic binning using current setttings.
  ds = 0.2 # setting can be changed to explore the best choice
  bin.size.limit = 24 # setting can be changed to explore the best choice. # here set as 5 just for the small example dataset. For real data, usually try 12 to 48.
  phylobin=taxa.binphy.big(tree = tree, pd.desc = pd.big$pd.file,pd.spname = pd.big$tip.label,
                           pd.wd = pd.big$pd.wd, ds = ds, bin.size.limit = bin.size.limit,
                           nworker = nworker)
  # 8.2 # test within-bin phylogenetic signal.
  sp.bin=phylobin$sp.bin[,3,drop=FALSE]
  sp.ra=colMeans(comm/rowSums(comm))
  abcut=3 # you may remove some species, if they are too rare to perform reliable correlation test.
  commc=comm[,colSums(comm)>=abcut,drop=FALSE]
  dim(commc)
  spname.use=colnames(commc)
  binps=iCAMP::ps.bin(sp.bin = sp.bin,sp.ra = sp.ra,spname.use = spname.use,
                      pd.desc = pd.big$pd.file, pd.spname = pd.big$tip.label, pd.wd = pd.big$pd.wd,
                      nd.list = niche.dif$nd,nd.spname = niche.dif$names,ndbig.wd = niche.dif$nd.wd,
                      cor.method = "pearson",r.cut = 0.1, p.cut = 0.05, min.spn = 5)
  if(file.exists(paste0(prefix,".PhyloSignalSummary.csv"))){appendy=TRUE;col.namesy=FALSE}else{appendy=FALSE;col.namesy=TRUE}
  write.table(data.frame(ds=ds,n.min=bin.size.limit,binps$Index),file = paste0(prefix,".PhyloSignalSummary.csv"),
              append = appendy, quote=FALSE, sep=",", row.names = FALSE,col.names = col.namesy)
  if(file.exists(paste0(prefix,".PhyloSignalDetail.csv"))){appendy2=TRUE;col.namesy2=FALSE}else{appendy2=FALSE;col.namesy2=TRUE}
  write.table(data.frame(ds=ds,n.min=bin.size.limit,binID=rownames(binps$detail),binps$detail),file = paste0(prefix,".PhyloSignalDetail.csv"),
              append = appendy2, quote = FALSE, sep = ",", row.names = FALSE, col.names = col.namesy2)
  # 9 # iCAMP analysis
  bin.size.limit = 24
  sig.index="Confidence" # see other options in help document of icamp.big.
  icres=iCAMP::icamp.big(comm=comm, pd.desc = pd.big$pd.file, pd.spname=pd.big$tip.label,
                         pd.wd = pd.big$pd.wd, rand = rand.time, tree=tree,
                         prefix = prefix, ds = 0.2, pd.cut = NA, sp.check = TRUE,
                         phylo.rand.scale = "within.bin", taxa.rand.scale = "across.all",
                         phylo.metric = "bMPD", sig.index=sig.index, bin.size.limit = bin.size.limit, 
                         nworker = nworker, memory.G = memory.G, rtree.save = FALSE, detail.save = TRUE, 
                         qp.save = FALSE, detail.null = FALSE, ignore.zero = TRUE, output.wd = save.wd, 
                         correct.special = TRUE, unit.sum = rowSums(comm), special.method = "depend",
                         ses.cut = 1.96, rc.cut = 0.95, conf.cut=0.975, omit.option = "no",meta.ab = NULL)
  setwd("F:/R")
  treat<-read.csv("treat_A.csv",header=T,row.names=1)
  # 10 # iCAMP bin level statistics
  icbin=icamp.bins(icamp.detail = icres$detail, treat = treat,silent=FALSE, boot = TRUE,
                   rand.time = rand.time,between.group = FALSE)
  save(icbin,file = paste0(prefix,".iCAMP.Summary.rda")) # just to archive the result. rda file is automatically compressed, and easy to load into R.
  write.csv(icbin$Pt,file = paste0(prefix,".ProcessImportance_EachGroup.csv"),row.names = FALSE)
  write.csv(icbin$Ptk,file = paste0(prefix,".ProcessImportance_EachBin_EachGroup.csv"),row.names = FALSE)
  write.csv(icbin$Ptuv,file = paste0(prefix,".ProcessImportance_EachTurnover.csv"),row.names = FALSE)
  write.csv(icbin$BPtk,file = paste0(prefix,".BinContributeToProcess_EachGroup.csv"),row.names = FALSE)
  
  write.csv(data.frame(ID=rownames(icbin$Class.Bin),icbin$Class.Bin,stringsAsFactors = FALSE),
            file = paste0(prefix,".Taxon_Bin.csv"),row.names = FALSE)
  write.csv(icbin$Bin.TopClass,file = paste0(prefix,".Bin_TopTaxon.csv"),row.names = FALSE)
  
  # cate<-clas
  # 
  # # 3 # summarize each category
  # icampcate=icamp.cate(icamp.bins.result = icbin, comm = comm, cate = cate,
  #                      treat = treat, silent = FALSE, between.group = FALSE)
  # 
  # write.csv(icampcate$Ptuvx,file = "16sRecahpairsample.csv",row.names = FALSE)
  # write.csv(icampcate$Ptx,file = "16sRamongsample.csv",row.names = FALSE)

library("RColorBrewer")
library("ggplot2")
library("reshape2")
library("dplyr")
library("melt")
install.packages(("melt"))
setwd("D:/")
mydata<-read.csv('iCAMP_all.csv',sep=",",na.strings="NA",stringsAsFactors=FALSE)
p2 <- ggplot(data=mydata.melt,aes(variable,value,fill=progress,stratum = progress, alluvium =progress)) +
  geom_stratum(color="black",width=0.6,size=0.5)+
  geom_flow(alpha = 0.5) +
  scale_fill_manual(values=c( 
    '#e76254', '#ef8a47', '#ffe6b7', '#72bcd5',
    '#528fad', '#8DD3C7')) +
  theme(
    axis.title=element_text(size=15,face="plain",color="black"),
    axis.text = element_text(size=15,face="plain",color="black"),
    legend.title=element_text(size=15,face="plain",color="black"),
    legend.position = "right",
    panel.background = element_blank(), 
    axis.line = element_line(colour = "black", linewidth = 0.5),
    panel.grid = element_blank()) + theme_bw() +
  theme(text=element_text(size=20)) +
  theme(axis.ticks.length=unit(-0.25, "cm"), 
        axis.text.x = element_text(margin=unit(c(0.5,0.5,0.5,0.5), "cm")), 
        axis.text.y = element_text(margin=unit(c(0.5,0.5,0.5,0.5), "cm")) )
p2
ggsave('iCAMP.pdf', p2, width = 8, height = 8)

##Figure 4D NCM
library(Hmisc)
library(minpack.lm)
library(stats4)
setwd("~/Documents/")
  spp<-read.csv("Totu.csv",header = T, stringsAsFactors=F,row.names = 1)
  spp<-t(spp)
N <- mean(apply(spp, 1, sum))
p.m <- apply(spp, 2, mean)
p.m <- p.m[p.m != 0]
p <- p.m/N
spp.bi <- 1*(spp>0)
freq <- apply(spp.bi, 2, mean)
freq <- freq[freq != 0]
C <- merge(p, freq, by=0)
C <- C[order(C[,2]),]
C <- as.data.frame(C)
C.0 <- C[!(apply(C, 1, function(y) any(y == 0))),]
p <- C.0[,2]
freq <- C.0[,3]
names(p) <- C.0[,1]
names(freq) <- C.0[,1]
d = 1/N
m.fit <- nlsLM(freq ~ pbeta(d, N*m*p, N*m*(1 -p), lower.tail=FALSE),start=list(m=0.1))
m.fit 
m.ci <- confint(m.fit, 'm', level=0.95)
freq.pred <- pbeta(d, N*coef(m.fit)*p, N*coef(m.fit)*(1 -p), lower.tail=FALSE)
pred.ci <- binconf(freq.pred*nrow(spp), nrow(spp), alpha=0.05, method="wilson", return.df=TRUE)
Rsqr <- 1 - (sum((freq - freq.pred)^2))/(sum((freq - mean(freq))^2))
Rsqr 
write.csv(p, file = "p.csv")
write.csv(freq, file = "freq.csv")
write.csv(freq.pred, file = "freq.pred.csv")
bacnlsALL <-data.frame(p,freq,freq.pred,pred.ci[,2:3])
inter.col<-rep('#bfbfbf',nrow(bacnlsALL))
inter.col[bacnlsALL$freq <= bacnlsALL$Lower]<-'#decbe4'
inter.col[bacnlsALL$freq >= bacnlsALL$Upper]<-'#fcb4ae'
library(grid)
grid.newpage()
pushViewport(viewport(h=0.6,w=0.6))
pushViewport(dataViewport(xData=range(log10(bacnlsALL$p)), yData=c(0,1.02),extension=c(0.02,0)))
grid.rect()
grid.points(log10(bacnlsALL$p), bacnlsALL$freq,pch=20,gp=gpar(col=inter.col,cex=0.7))
grid.yaxis()
grid.xaxis()
grid.lines(log10(bacnlsALL$p),bacnlsALL$freq.pred,gp=gpar(col='#ffd9a6',lwd=2),default='native')
grid.lines(log10(bacnlsALL$p),bacnlsALL$Lower ,gp=gpar(col='#ffd9a6',lwd=2,lty=2),default='native') 
grid.lines(log10(bacnlsALL$p),bacnlsALL$Upper,gp=gpar(col='#ffd9a6',lwd=2,lty=2),default='native') 
grid.text(y=unit(0,'npc')-unit(2.5,'lines'),label='Mean Relative Abundance (log10)', gp=gpar(fontface=2)) 
grid.text(x=unit(0,'npc')-unit(3,'lines'),label='Frequency of Occurance',gp=gpar(fontface=2),rot=90) 
#grid.text(x=unit(0,'npc')-unit(-1,'lines'), y=unit(0,'npc')-unit(-15,'lines'),label='Mean Relative Abundance (log)', gp=gpar(fontface=2)) 
#grid.text(round(coef(m.fit)*N),x=unit(0,'npc')-unit(-5,'lines'), y=unit(0,'npc')-unit(-15,'lines'),gp=gpar(fontface=2)) 
#grid.text(label = "Nm=",x=unit(0,'npc')-unit(-3,'lines'), y=unit(0,'npc')-unit(-15,'lines'),gp=gpar(fontface=2))
#grid.text(round(Rsqr,2),x=unit(0,'npc')-unit(-5,'lines'), y=unit(0,'npc')-unit(-16,'lines'),gp=gpar(fontface=2))
#grid.text(label = "Rsqr=",x=unit(0,'npc')-unit(-3,'lines'), y=unit(0,'npc')-unit(-16,'lines'),gp=gpar(fontface=2))
draw.text <- function(just, i, j) {
  grid.text(paste("Rsqr=",round(Rsqr,3),"\n","Nm=",round(coef(m.fit)*N)), x=x[j], y=y[i], just=just)
  #grid.text(deparse(substitute(just)), x=x[j], y=y[i] + unit(2, "lines"),
  #          gp=gpar(col="grey", fontsize=8))
}
x <- unit(1:4/5, "npc")
y <- unit(1:4/5, "npc")
draw.text(c("centre", "bottom"), 4, 1)

setwd("~/Documents/")
  spp<-read.csv("Dotu.csv",header = T, stringsAsFactors=F,row.names = 1)
  spp<-t(spp)
N <- mean(apply(spp, 1, sum))
p.m <- apply(spp, 2, mean)
p.m <- p.m[p.m != 0]
p <- p.m/N
spp.bi <- 1*(spp>0)
freq <- apply(spp.bi, 2, mean)
freq <- freq[freq != 0]
C <- merge(p, freq, by=0)
C <- C[order(C[,2]),]
C <- as.data.frame(C)
C.0 <- C[!(apply(C, 1, function(y) any(y == 0))),]
p <- C.0[,2]
freq <- C.0[,3]
names(p) <- C.0[,1]
names(freq) <- C.0[,1]
d = 1/N
m.fit <- nlsLM(freq ~ pbeta(d, N*m*p, N*m*(1 -p), lower.tail=FALSE),start=list(m=0.1))
m.fit 
m.ci <- confint(m.fit, 'm', level=0.95)
freq.pred <- pbeta(d, N*coef(m.fit)*p, N*coef(m.fit)*(1 -p), lower.tail=FALSE)
pred.ci <- binconf(freq.pred*nrow(spp), nrow(spp), alpha=0.05, method="wilson", return.df=TRUE)
Rsqr <- 1 - (sum((freq - freq.pred)^2))/(sum((freq - mean(freq))^2))
Rsqr 
write.csv(p, file = "p.csv")
write.csv(freq, file = "freq.csv")
write.csv(freq.pred, file = "freq.pred.csv")
bacnlsALL <-data.frame(p,freq,freq.pred,pred.ci[,2:3])
inter.col<-rep('#bfbfbf',nrow(bacnlsALL))
inter.col[bacnlsALL$freq <= bacnlsALL$Lower]<-'#decbe4'
inter.col[bacnlsALL$freq >= bacnlsALL$Upper]<-'#fcb4ae'
library(grid)
grid.newpage()
pushViewport(viewport(h=0.6,w=0.6))
pushViewport(dataViewport(xData=range(log10(bacnlsALL$p)), yData=c(0,1.02),extension=c(0.02,0)))
grid.rect()
grid.points(log10(bacnlsALL$p), bacnlsALL$freq,pch=20,gp=gpar(col=inter.col,cex=0.7))
grid.yaxis()
grid.xaxis()
grid.lines(log10(bacnlsALL$p),bacnlsALL$freq.pred,gp=gpar(col='#ffd9a6',lwd=2),default='native')
grid.lines(log10(bacnlsALL$p),bacnlsALL$Lower ,gp=gpar(col='#ffd9a6',lwd=2,lty=2),default='native') 
grid.lines(log10(bacnlsALL$p),bacnlsALL$Upper,gp=gpar(col='#ffd9a6',lwd=2,lty=2),default='native') 
grid.text(y=unit(0,'npc')-unit(2.5,'lines'),label='Mean Relative Abundance (log10)', gp=gpar(fontface=2)) 
grid.text(x=unit(0,'npc')-unit(3,'lines'),label='Frequency of Occurance',gp=gpar(fontface=2),rot=90) 
#grid.text(x=unit(0,'npc')-unit(-1,'lines'), y=unit(0,'npc')-unit(-15,'lines'),label='Mean Relative Abundance (log)', gp=gpar(fontface=2)) 
#grid.text(round(coef(m.fit)*N),x=unit(0,'npc')-unit(-5,'lines'), y=unit(0,'npc')-unit(-15,'lines'),gp=gpar(fontface=2)) 
#grid.text(label = "Nm=",x=unit(0,'npc')-unit(-3,'lines'), y=unit(0,'npc')-unit(-15,'lines'),gp=gpar(fontface=2))
#grid.text(round(Rsqr,2),x=unit(0,'npc')-unit(-5,'lines'), y=unit(0,'npc')-unit(-16,'lines'),gp=gpar(fontface=2))
#grid.text(label = "Rsqr=",x=unit(0,'npc')-unit(-3,'lines'), y=unit(0,'npc')-unit(-16,'lines'),gp=gpar(fontface=2))
draw.text <- function(just, i, j) {
  grid.text(paste("Rsqr=",round(Rsqr,3),"\n","Nm=",round(coef(m.fit)*N)), x=x[j], y=y[i], just=just)
  #grid.text(deparse(substitute(just)), x=x[j], y=y[i] + unit(2, "lines"),
  #          gp=gpar(col="grey", fontsize=8))
}
x <- unit(1:4/5, "npc")
y <- unit(1:4/5, "npc")
draw.text(c("centre", "bottom"), 4, 1)

setwd("~/Documents/")
  spp<-read.csv("Sotu.csv",header = T, stringsAsFactors=F,row.names = 1)
  spp<-t(spp)
N <- mean(apply(spp, 1, sum))
p.m <- apply(spp, 2, mean)
p.m <- p.m[p.m != 0]
p <- p.m/N
spp.bi <- 1*(spp>0)
freq <- apply(spp.bi, 2, mean)
freq <- freq[freq != 0]
C <- merge(p, freq, by=0)
C <- C[order(C[,2]),]
C <- as.data.frame(C)
C.0 <- C[!(apply(C, 1, function(y) any(y == 0))),]
p <- C.0[,2]
freq <- C.0[,3]
names(p) <- C.0[,1]
names(freq) <- C.0[,1]
d = 1/N
m.fit <- nlsLM(freq ~ pbeta(d, N*m*p, N*m*(1 -p), lower.tail=FALSE),start=list(m=0.1))
m.fit 
m.ci <- confint(m.fit, 'm', level=0.95)
freq.pred <- pbeta(d, N*coef(m.fit)*p, N*coef(m.fit)*(1 -p), lower.tail=FALSE)
pred.ci <- binconf(freq.pred*nrow(spp), nrow(spp), alpha=0.05, method="wilson", return.df=TRUE)
Rsqr <- 1 - (sum((freq - freq.pred)^2))/(sum((freq - mean(freq))^2))
Rsqr 
write.csv(p, file = "p.csv")
write.csv(freq, file = "freq.csv")
write.csv(freq.pred, file = "freq.pred.csv")
bacnlsALL <-data.frame(p,freq,freq.pred,pred.ci[,2:3])
inter.col<-rep('#bfbfbf',nrow(bacnlsALL))
inter.col[bacnlsALL$freq <= bacnlsALL$Lower]<-'#decbe4'
inter.col[bacnlsALL$freq >= bacnlsALL$Upper]<-'#fcb4ae'
library(grid)
grid.newpage()
pushViewport(viewport(h=0.6,w=0.6))
pushViewport(dataViewport(xData=range(log10(bacnlsALL$p)), yData=c(0,1.02),extension=c(0.02,0)))
grid.rect()
grid.points(log10(bacnlsALL$p), bacnlsALL$freq,pch=20,gp=gpar(col=inter.col,cex=0.7))
grid.yaxis()
grid.xaxis()
grid.lines(log10(bacnlsALL$p),bacnlsALL$freq.pred,gp=gpar(col='#ffd9a6',lwd=2),default='native')
grid.lines(log10(bacnlsALL$p),bacnlsALL$Lower ,gp=gpar(col='#ffd9a6',lwd=2,lty=2),default='native') 
grid.lines(log10(bacnlsALL$p),bacnlsALL$Upper,gp=gpar(col='#ffd9a6',lwd=2,lty=2),default='native') 
grid.text(y=unit(0,'npc')-unit(2.5,'lines'),label='Mean Relative Abundance (log10)', gp=gpar(fontface=2)) 
grid.text(x=unit(0,'npc')-unit(3,'lines'),label='Frequency of Occurance',gp=gpar(fontface=2),rot=90) 
#grid.text(x=unit(0,'npc')-unit(-1,'lines'), y=unit(0,'npc')-unit(-15,'lines'),label='Mean Relative Abundance (log)', gp=gpar(fontface=2)) 
#grid.text(round(coef(m.fit)*N),x=unit(0,'npc')-unit(-5,'lines'), y=unit(0,'npc')-unit(-15,'lines'),gp=gpar(fontface=2)) 
#grid.text(label = "Nm=",x=unit(0,'npc')-unit(-3,'lines'), y=unit(0,'npc')-unit(-15,'lines'),gp=gpar(fontface=2))
#grid.text(round(Rsqr,2),x=unit(0,'npc')-unit(-5,'lines'), y=unit(0,'npc')-unit(-16,'lines'),gp=gpar(fontface=2))
#grid.text(label = "Rsqr=",x=unit(0,'npc')-unit(-3,'lines'), y=unit(0,'npc')-unit(-16,'lines'),gp=gpar(fontface=2))
draw.text <- function(just, i, j) {
  grid.text(paste("Rsqr=",round(Rsqr,3),"\n","Nm=",round(coef(m.fit)*N)), x=x[j], y=y[i], just=just)
  #grid.text(deparse(substitute(just)), x=x[j], y=y[i] + unit(2, "lines"),
  #          gp=gpar(col="grey", fontsize=8))
}
x <- unit(1:4/5, "npc")
y <- unit(1:4/5, "npc")
draw.text(c("centre", "bottom"), 4, 1)

setwd("~/Documents/")
  spp<-read.csv("Potu.csv",header = T, stringsAsFactors=F,row.names = 1)
  spp<-t(spp)
N <- mean(apply(spp, 1, sum))
p.m <- apply(spp, 2, mean)
p.m <- p.m[p.m != 0]
p <- p.m/N
spp.bi <- 1*(spp>0)
freq <- apply(spp.bi, 2, mean)
freq <- freq[freq != 0]
C <- merge(p, freq, by=0)
C <- C[order(C[,2]),]
C <- as.data.frame(C)
C.0 <- C[!(apply(C, 1, function(y) any(y == 0))),]
p <- C.0[,2]
freq <- C.0[,3]
names(p) <- C.0[,1]
names(freq) <- C.0[,1]
d = 1/N
m.fit <- nlsLM(freq ~ pbeta(d, N*m*p, N*m*(1 -p), lower.tail=FALSE),start=list(m=0.1))
m.fit 
m.ci <- confint(m.fit, 'm', level=0.95)
freq.pred <- pbeta(d, N*coef(m.fit)*p, N*coef(m.fit)*(1 -p), lower.tail=FALSE)
pred.ci <- binconf(freq.pred*nrow(spp), nrow(spp), alpha=0.05, method="wilson", return.df=TRUE)
Rsqr <- 1 - (sum((freq - freq.pred)^2))/(sum((freq - mean(freq))^2))
Rsqr 
write.csv(p, file = "p.csv")
write.csv(freq, file = "freq.csv")
write.csv(freq.pred, file = "freq.pred.csv")
bacnlsALL <-data.frame(p,freq,freq.pred,pred.ci[,2:3])
inter.col<-rep('#bfbfbf',nrow(bacnlsALL))
inter.col[bacnlsALL$freq <= bacnlsALL$Lower]<-'#decbe4'
inter.col[bacnlsALL$freq >= bacnlsALL$Upper]<-'#fcb4ae'
library(grid)
grid.newpage()
pushViewport(viewport(h=0.6,w=0.6))
pushViewport(dataViewport(xData=range(log10(bacnlsALL$p)), yData=c(0,1.02),extension=c(0.02,0)))
grid.rect()
grid.points(log10(bacnlsALL$p), bacnlsALL$freq,pch=20,gp=gpar(col=inter.col,cex=0.7))
grid.yaxis()
grid.xaxis()
grid.lines(log10(bacnlsALL$p),bacnlsALL$freq.pred,gp=gpar(col='#ffd9a6',lwd=2),default='native')
grid.lines(log10(bacnlsALL$p),bacnlsALL$Lower ,gp=gpar(col='#ffd9a6',lwd=2,lty=2),default='native') 
grid.lines(log10(bacnlsALL$p),bacnlsALL$Upper,gp=gpar(col='#ffd9a6',lwd=2,lty=2),default='native') 
grid.text(y=unit(0,'npc')-unit(2.5,'lines'),label='Mean Relative Abundance (log10)', gp=gpar(fontface=2)) 
grid.text(x=unit(0,'npc')-unit(3,'lines'),label='Frequency of Occurance',gp=gpar(fontface=2),rot=90) 
#grid.text(x=unit(0,'npc')-unit(-1,'lines'), y=unit(0,'npc')-unit(-15,'lines'),label='Mean Relative Abundance (log)', gp=gpar(fontface=2)) 
#grid.text(round(coef(m.fit)*N),x=unit(0,'npc')-unit(-5,'lines'), y=unit(0,'npc')-unit(-15,'lines'),gp=gpar(fontface=2)) 
#grid.text(label = "Nm=",x=unit(0,'npc')-unit(-3,'lines'), y=unit(0,'npc')-unit(-15,'lines'),gp=gpar(fontface=2))
#grid.text(round(Rsqr,2),x=unit(0,'npc')-unit(-5,'lines'), y=unit(0,'npc')-unit(-16,'lines'),gp=gpar(fontface=2))
#grid.text(label = "Rsqr=",x=unit(0,'npc')-unit(-3,'lines'), y=unit(0,'npc')-unit(-16,'lines'),gp=gpar(fontface=2))
draw.text <- function(just, i, j) {
  grid.text(paste("Rsqr=",round(Rsqr,3),"\n","Nm=",round(coef(m.fit)*N)), x=x[j], y=y[i], just=just)
  #grid.text(deparse(substitute(just)), x=x[j], y=y[i] + unit(2, "lines"),
  #          gp=gpar(col="grey", fontsize=8))
}
x <- unit(1:4/5, "npc")
y <- unit(1:4/5, "npc")
draw.text(c("centre", "bottom"), 4, 1)

setwd("~/Documents/")
  spp<-read.csv("Rotu.csv",header = T, stringsAsFactors=F,row.names = 1)
  spp<-t(spp)
N <- mean(apply(spp, 1, sum))
p.m <- apply(spp, 2, mean)
p.m <- p.m[p.m != 0]
p <- p.m/N
spp.bi <- 1*(spp>0)
freq <- apply(spp.bi, 2, mean)
freq <- freq[freq != 0]
C <- merge(p, freq, by=0)
C <- C[order(C[,2]),]
C <- as.data.frame(C)
C.0 <- C[!(apply(C, 1, function(y) any(y == 0))),]
p <- C.0[,2]
freq <- C.0[,3]
names(p) <- C.0[,1]
names(freq) <- C.0[,1]
d = 1/N
m.fit <- nlsLM(freq ~ pbeta(d, N*m*p, N*m*(1 -p), lower.tail=FALSE),start=list(m=0.1))
m.fit 
m.ci <- confint(m.fit, 'm', level=0.95)
freq.pred <- pbeta(d, N*coef(m.fit)*p, N*coef(m.fit)*(1 -p), lower.tail=FALSE)
pred.ci <- binconf(freq.pred*nrow(spp), nrow(spp), alpha=0.05, method="wilson", return.df=TRUE)
Rsqr <- 1 - (sum((freq - freq.pred)^2))/(sum((freq - mean(freq))^2))
Rsqr 
write.csv(p, file = "p.csv")
write.csv(freq, file = "freq.csv")
write.csv(freq.pred, file = "freq.pred.csv")
bacnlsALL <-data.frame(p,freq,freq.pred,pred.ci[,2:3])
inter.col<-rep('#bfbfbf',nrow(bacnlsALL))
inter.col[bacnlsALL$freq <= bacnlsALL$Lower]<-'#decbe4'
inter.col[bacnlsALL$freq >= bacnlsALL$Upper]<-'#fcb4ae'
library(grid)
grid.newpage()
pushViewport(viewport(h=0.6,w=0.6))
pushViewport(dataViewport(xData=range(log10(bacnlsALL$p)), yData=c(0,1.02),extension=c(0.02,0)))
grid.rect()
grid.points(log10(bacnlsALL$p), bacnlsALL$freq,pch=20,gp=gpar(col=inter.col,cex=0.7))
grid.yaxis()
grid.xaxis()
grid.lines(log10(bacnlsALL$p),bacnlsALL$freq.pred,gp=gpar(col='#ffd9a6',lwd=2),default='native')
grid.lines(log10(bacnlsALL$p),bacnlsALL$Lower ,gp=gpar(col='#ffd9a6',lwd=2,lty=2),default='native') 
grid.lines(log10(bacnlsALL$p),bacnlsALL$Upper,gp=gpar(col='#ffd9a6',lwd=2,lty=2),default='native') 
grid.text(y=unit(0,'npc')-unit(2.5,'lines'),label='Mean Relative Abundance (log10)', gp=gpar(fontface=2)) 
grid.text(x=unit(0,'npc')-unit(3,'lines'),label='Frequency of Occurance',gp=gpar(fontface=2),rot=90) 
#grid.text(x=unit(0,'npc')-unit(-1,'lines'), y=unit(0,'npc')-unit(-15,'lines'),label='Mean Relative Abundance (log)', gp=gpar(fontface=2)) 
#grid.text(round(coef(m.fit)*N),x=unit(0,'npc')-unit(-5,'lines'), y=unit(0,'npc')-unit(-15,'lines'),gp=gpar(fontface=2)) 
#grid.text(label = "Nm=",x=unit(0,'npc')-unit(-3,'lines'), y=unit(0,'npc')-unit(-15,'lines'),gp=gpar(fontface=2))
#grid.text(round(Rsqr,2),x=unit(0,'npc')-unit(-5,'lines'), y=unit(0,'npc')-unit(-16,'lines'),gp=gpar(fontface=2))
#grid.text(label = "Rsqr=",x=unit(0,'npc')-unit(-3,'lines'), y=unit(0,'npc')-unit(-16,'lines'),gp=gpar(fontface=2))
draw.text <- function(just, i, j) {
  grid.text(paste("Rsqr=",round(Rsqr,3),"\n","Nm=",round(coef(m.fit)*N)), x=x[j], y=y[i], just=just)
  #grid.text(deparse(substitute(just)), x=x[j], y=y[i] + unit(2, "lines"),
  #          gp=gpar(col="grey", fontsize=8))
}
x <- unit(1:4/5, "npc")
y <- unit(1:4/5, "npc")
draw.text(c("centre", "bottom"), 4, 1)
