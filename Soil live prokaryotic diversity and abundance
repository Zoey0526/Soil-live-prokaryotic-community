The comparison of live soil prokaryotic abundance and diversity using different methods
##Figure 1
library(vegan)
library(permute)
library(lattice)
setwd("D:/")
Bfn1<-read.csv("otutab_its.csv", header=TRUE, row.names=1)
Bfn<-t(Bfn1)
S1 <- specnumber(Bfn)
(raremax1 <- min(rowSums(Bfn)))
 newOTU <- rrarefy(Bfn, raremax1)
newOTU1 = t(newOTU)
write.csv(newOTU1,file='ES_otu_delete_rare.csv')
##diversity
##shannon
library(vegan)
library(ggplot2)
library(ggpubr)
library(ggsci)
setwd("D:/")
species<-read.csv("alpha_16S.csv",header=T,row.names = 1)
species$treat<-as.factor(species$treat)
species$ID<-as.factor(species$ID)
species$treat <- factor(species$treat,levels = c("T","D","S","P","R"))
shapiro <- tapply(species$shannon, species$treat, shapiro.test)
shapiro
bartlett.test(shannon ~ treat, data=species)
library(rstatix)
res.aov<-anova_test(data = species, dv = evenness,   wid= ID, within =  treat)
get_anova_table(res.aov)
####################################################################
#####################################################################
scaleFUN<-  function(x) sprintf ("%.1f",x)
#colnames(species)<-c("Row.names","species","type")
species$group<-c(1:52,1:52,1:52,1:52,1:52)

my_comparisons <- list(c("T", "D"),  c("T", "S")  
                       , c("T", "R"))
my_comparisons <- list(c("T", "D"),  c("T", "S"),  c("T", "P")
                       , c("T", "R"),  c("D", "S"),  c("D", "P")
                       ,  c("D", "R"),  c("S", "P"),  c("S", "R")
                       ,  c("P", "R"))
p4 = ggplot(species,aes(fill = treat,x=factor(treat,level=c("T","D","S","P","R")), y=shannon))+###abundance： y=species
  stat_boxplot(geom="errorbar",width=0.15)+
  geom_boxplot(alpha=0.7,aes(fill=treat))+
  geom_line(aes(group=group) ,colour="#9C9C9C",lwd=0.2)+
  geom_point(size = 0.5)+
  scale_y_continuous(name="Prokaryotic Shannon",labels=scaleFUN)+
  theme_bw()+
  theme(legend.position='none')+
  theme(panel.background = element_rect(fill = "white", colour = "black"), 
        panel.grid = element_blank(),
        panel.border = element_blank(),
        text = element_text(colour="black",size=14),
        axis.title = element_text(colour="black",face="bold"),
        axis.text=element_text(colour="black",size=14),
        axis.title.x = element_blank(),
        axis.title.y = element_text(colour="black", size = 14))+
        #xlab("")+ylab("Prokaryotic richness(103)")+ylim(2,12)+
   #scale_x_discrete(labels = c("D1","D3","D6","D12","D24","D48"))+ 
  stat_compare_means(comparisons=my_comparisons,label ="p.signif",step_increase = 0.1,map_signif_level = T,test = wilcox.test,paired = TRUE) # Add pairwise 
   #stat_compare_means(label.y = 9,label.x = 1.5,size=6) # Add global p-value

p4<-p4+scale_fill_brewer(palette = "Set3",direction = -1) ##palette = "Blues"
p4
ggsave('shannon.pdf', p4, width = 4, height = 4)

mod1 = aov(shannon ~ treat, data= species)
summary(mod1)
re = LSD.test(mod1,"treat",alpha = 0.05)
re1 = re$groups
re1
print(re)
##richness
library(vegan)
library(ggplot2)
library(ggpubr)
library(ggsci)
setwd("E:\")
species<-read.csv("alpha_16S.csv",header=T,row.names = 1)
species$treat<-as.factor(species$treat)
species$ID<-as.factor(species$ID)
species$treat <- factor(species$treat,levels = c("T","D","S","P","R"))
shapiro <- tapply(species$richness, species$treat, shapiro.test)
shapiro
bartlett.test(richness ~ treat, data=species)
library(rstatix)
res.aov<-anova_test(data = species, dv = richness,   wid= ID, within =  treat)
get_anova_table(res.aov)
scaleFUN<-  function(x) sprintf ("%.1f",x)
#colnames(species)<-c("Row.names","species","type")
species$group<-c(1:52,1:52,1:52,1:52,1:52)
my_comparisons <- list(c("T", "D")
                       , c("T", "R"),    c("D", "P"))
p4 = ggplot(species,aes(fill = treat,x=factor(treat,level=c("T","D","S","P","R")), y=richness/1000))+###abundance： y=species
  stat_boxplot(geom="errorbar",width=0.15)+
  geom_boxplot(alpha=0.7,aes(fill=treat))+
  geom_line(aes(group=group) ,colour="#9C9C9C",lwd=0.2)+
  geom_point(size = 0.5)+
  scale_y_continuous(name="Prokaryotic Richness(103)",labels=scaleFUN)+
  scale_x_discrete(name="treat")+
  theme_bw()+
  theme(legend.position='none')+
  theme(panel.background = element_rect(fill = "white", colour = "black"),
        panel.grid = element_blank(),
        panel.border = element_blank(),
        text = element_text(colour="black",size=14),
        axis.title = element_text(colour="black",face="bold"),
        axis.text=element_text(colour="black",size=14),
        axis.title.x = element_blank(),
        axis.title.y = element_text(colour="black", size = 14))+
  #xlab("")+ylab("Prokaryotic richness(103)")+ylim(2,12)+
  #scale_x_discrete(labels = c("D1","D3","D6","D12","D24","D48"))+
  stat_compare_means(comparisons=my_comparisons,label ="p.signif",step_increase = 0.1,map_signif_level = T,test = wilcox.test,paired = TRUE) # Add pairwise 
  #stat_compare_means(label.y = 10,label.x = 1.5,size=6) # Add global p-value

p4<-p4+scale_fill_brewer(palette = "Set3",direction = -1)
p4
ggsave('richness.pdf', p4, width = 4, height = 4)
##Copies
library(vegan)
library(ggplot2)
library(ggpubr)
library(ggsci)
setwd("D:/")
species<-read.csv("Copies.csv",header=T,row.names = 1)
species$treat<-as.factor(species$treat)
species$ID<-as.factor(species$ID)
species$treat <- factor(species$treat,levels = c("T","D","S","P","R"))
shapiro <- tapply(species$copies, species$treat, shapiro.test)
shapiro
bartlett.test(copies ~ treat, data=species)
library(rstatix)
res.aov<-anova_test(data = species, dv = copies,   wid= ID, within =  treat)
get_anova_table(res.aov)
scaleFUN<-  function(x) sprintf ("%.1f",x)
#colnames(species)<-c("Row.names","species","type")
species$group<-c(1:52,1:52,1:52,1:52,1:52)
my_comparisons <- list(c("T", "D"),  c("T", "P")
                       ,  c("D", "S"))
p4 = ggplot(species,aes(fill = treat,x=factor(treat,level=c("T","D","S","P","R")), y=copies))+###abundance： y=species
  stat_boxplot(geom="errorbar",width=0.15)+
  geom_boxplot(alpha=0.7,aes(fill=treat))+
  geom_line(aes(group=group) ,colour="#9C9C9C",lwd=0.2)+
  geom_point(size = 0.5)+
  scale_y_continuous(name="Prokaryotic Copies(lg)",labels=scaleFUN)+
  scale_x_discrete(name="Nucleic acid extraction method")+
  theme_bw()+
  theme(legend.position='none')+
  theme(panel.background = element_rect(fill = "white", colour = "black"),
        panel.grid = element_blank(),
        panel.border = element_blank(),
        text = element_text(colour="black",size=14),
        axis.title = element_text(colour="black",face="bold"),
        axis.text=element_text(colour="black",size=14),
        axis.title.x = element_blank(),
        axis.title.y = element_text(colour="black", size = 14))+
  #xlab("")+ylab("Prokaryotic richness(103)")+ylim(2,12)+
  #scale_x_discrete(labels = c("D1","D3","D6","D12","D24","D48"))+
  stat_compare_means(comparisons=my_comparisons,label ="p.signif",step_increase = 0.1,map_signif_level = T,test = wilcox.test,paired = TRUE) # Add pairwise 
  #stat_compare_means(label.y = 10,label.x = 1.5,size=6) # Add global p-value

p4<-p4+scale_fill_brewer(palette = "Set3",direction = -1) 
p4
ggsave('copies.pdf', p4, width = 4, height = 4)
mod1 = aov(richness ~ treat, data= species)
summary(mod1)
re = LSD.test(mod1,"treat",alpha = 0.05)
re1 = re$groups
re1
print(re)
setwd("D:")
  species<-read.csv("BC similarity.csv",header=T)
  species$type<-as.factor(species$type)
  species$ID<-as.factor(species$ID)
  shapiro <- tapply(species$value, species$type, shapiro.test)
  shapiro
  bartlett.test(value ~ type, data=species)
  library(rstatix)
  res.aov<-anova_test(data = species, dv = value,   wid= ID, within =  type)
  get_anova_table(res.aov)
  scaleFUN<-  function(x) sprintf ("%.1f",x)
  #colnames(species)<-c("Row.names","species","type")
  species$group<-c(1:52,1:52,1:52,1:52)
  
  p4 = ggplot(species,aes(fill = type,x=factor(type,level=c("S/T","D/T","P/T","R/T")), y=value))+abundance： y=species
    stat_boxplot(geom="errorbar",width=0.15)+
    geom_boxplot(alpha=0.7,aes(fill=type))+
    geom_line(aes(group=group) ,colour="#9C9C9C",lwd=0.2)+
    geom_point(size = 0.5)+
    scale_y_continuous(name="Bray-Curtis Similarity",labels=scaleFUN)+
    scale_x_discrete(name="Treat")+
    theme_bw()+
    theme(legend.position='none')+
    theme(panel.background = element_rect(fill = "white", colour = "black"), 
          panel.grid = element_blank(),
          panel.border = element_blank(),
          text = element_text(colour="black",size=14),
          axis.title = element_text(colour="black",face="bold"),
          axis.text=element_text(colour="black",size=14),
          axis.title.x = element_blank(),
          axis.title.y = element_text(colour="black", size = 12))+
    xlab("Treat")+ylab("Bray-Curtis similarity ")+coord_cartesian(ylim = c(0.15,0.8))+
    #stat_compare_means(comparisons=my_comparisons,label ="p.signif",step_increase = 0.1,map_signif_level = T,test = wilcox.test,paired = TRUE) # Add pairwise 
    stat_compare_means(label.y = 0.58,label.x = 3,size=5) # Add global p-value
  
  p4<-p4+scale_fill_brewer(palette = "Dark2") ##palette = "Blues"
  p4
  ggsave('Total.pdf', p4, width = 7, height = 5)


##Figure 2

##
library(permute)
library(vegan)
setwd('D:/')
OTU_Tax16sCP <-read.csv("OTU_rare_TS.csv", header=TRUE,check.names = F)
#Domain=aggregate(x=OTU_Tax16sCP[,2:101]/51565,by=list(OTU_Tax16sCP$Domain),FUN='sum')
#write.csv(Domain, file = " Domain_16S.csv")
datacol = ncol(OTU_Tax16sCP)-7
colSums(OTU_Tax16sCP[2:datacol])
rare = sum(OTU_Tax16sCP[,2])
Kingdom=aggregate(x=OTU_Tax16sCP[,2:datacol]/rare,by=list(OTU_Tax16sCP$Kingdom),FUN='sum')
Phylum=aggregate(x=OTU_Tax16sCP[,2:datacol]/rare,by=list(OTU_Tax16sCP$Phylum),FUN='sum')
colSums(Phylum[,2:datacol])
all <-  Kingdom
precount <- nrow(all)
for (i in 1:nrow(Phylum)) {
  all[precount+i,] <- Phylum[i,]}
Class=aggregate(x=OTU_Tax16sCP[,2:datacol]/rare,by=list(OTU_Tax16sCP$Class),FUN='sum')
precount <- nrow(all)
for (i in 1:nrow(Class)) {
  all[precount+i,] <- Class[i,]}
Order=aggregate(x=OTU_Tax16sCP[,2:datacol]/rare,by=list(OTU_Tax16sCP$Order),FUN='sum')
precount <- nrow(all)
for (i in 1:nrow(Order)) {
  all[precount+i,] <- Order[i,]}
Family=aggregate(x=OTU_Tax16sCP[,2:datacol]/rare,by=list(OTU_Tax16sCP$Family),FUN='sum')
precount <- nrow(all)
for (i in 1:nrow(Family)) {
  all[precount+i,] <- Family[i,]}
Genus=aggregate(x=OTU_Tax16sCP[,2:datacol]/rare,by=list(OTU_Tax16sCP$Genus),FUN='sum')
precount <- nrow(all)
for (i in 1:nrow(Genus)) {
  all[precount+i,] <- Genus[i,]}
write.csv(all, file = "TS.csv",row.names = FALSE)
colSums(Phylum[,2:datacol])
colSums(Class[,2:datacol])
colSums(Order[,2:datacol])
colSums(Family[,2:datacol])
colSums(Genus[,2:datacol])
all$average = rowMeans(all[,2:datacol])
screen0.0001 <-all
result <- subset(screen0.0001[which(screen0.0001$average>0.0005),])
write.csv(result[,1:ncol(result)-1], file = "TS.csv",row.names = FALSE)
library(reshape2)
data <-read.csv("TS.csv", header=TRUE,row.names = 1)
group <- read.csv(file = "group_TS.csv",header = F)
data <- data[, match(group[, 1], colnames(data))]
write.csv(data, file = "TS.csv",row.names = TRUE)
lengthData = ncol(data)
pvalue = apply(data,1,function(x) wilcox.test(x[1:(lengthData/2)],x[(lengthData/2+1):lengthData],paired = T,alternative="two.sided",conf.level=0.95)$p.value)
#tvalue=apply(data,1,function(x)  wilcox.test(x[2:31],x[32:61],paired = T,alternative="two.sided",conf.level=0.95)$statistic)
write.csv(pvalue, 'pvalue_TS.csv')
data1 = data
data1$suma = rowSums(data1[, 1:(lengthData/2)])
data1$sumb = rowSums(data1[, (lengthData/2+1):lengthData])
data1$p = pvalue
data2 = data1[which(data1$p!='NaN'& data1$p < 0.1),]
summary(data2$p)
data3 = subset(data2,select = c(suma,sumb,p))
data3$sum = data3$suma+data3$sumb
data3$sub = data3$suma-data3$sumb
data3$clade_marker_size = "clade_marker_size"
data3$clade_value = 6*log(data3$sum*10000)
data3$clade_marker_color = "clade_marker_color"
data3$color_value = ifelse(data3$sub > 0, '#FCB4AE', '#B3E2CD')
name <- rownames(data3)
data3$finalName = sapply(strsplit(name, "\\."), function(x) tail(x, n = 1)) 
data3$annotation_background_color = "annotation_background_color"
data3$bkcolor = data3$color_value
write.csv(data3,"TS.csv",row.names = T)

python graphlan_annotate.py --annot annot_0.txt guide_16s.txt guide_1.xml
python graphlan.py guide_1.xml step_1_2.pdf --dpi 300 --size 3.5
 
python graphlan_annotate.py --annot annot_1.txt guide_1.xml guide_2.xml
python graphlan.py guide_2.xml step_2_5.pdf --dpi 300 --size 3.5
 
python graphlan_annotate.py --annot annot_2.txt guide_2.xml guide_3.xml
python graphlan.py guide_3.xml step_3_2.pdf --dpi 300 --size 3.5


##Figure3
##co-occurance network 
  library(Hmisc)
  library(psych)
  library(igraph)
  library(Formula)
  setwd("D:/")
  otu <- read.csv('otuBF_781.csv', row.name = 1, check.names = FALSE)
  otu1 <- otu
  otu1[otu1>0] <- 1
  otu <- otu[which(rowSums(otu1) >= 25 ),]
  #write.table(otu, 'remove_60.txt', sep = '\t', row.names = TRUE)
  rowsum <- as.data.frame(rowSums(otu))
  sum <- colSums(rowsum)
  otu$RA <- rowsum/sum
  #otu <- otu[which(otu$RA>0.0001),]
  otu <- subset(otu[which(otu$RA>0.0001),], select = -RA)
  otu <- t(otu)
  otu <- scale(otu)
  rcorr_otu <- rcorr(as.matrix(otu), type = 'spearman')
  #corr_otu <- corr.test(otu, method = 'spearman')
  #rcorr_otu
  p <- rcorr_otu$P
  #p <- p.adjust(p, method = 'BH')
  r <- rcorr_otu$r
  r[which(r < 0)]
  r[abs(r) < 0.8] <- 0
  #write.table(r, 'corr_r_0.6.txt', sep = '\t', row.names = TRUE)
  p[p>=0.05] <- -1
  p[p<0.05 & p>=0] <- 1
  p[p==-1] <- 0
  z <- r * p
  z[which(z < 0)]
  #z <- na.omit(z)
  # write.table(data.frame(z1, check.names = FALSE), 'z1.txt', col.names = NA, sep = '\t', quote = FALSE)
  g <- graph.adjacency(z, weighted = TRUE, mode = 'undirected', diag = FALSE)
  g <- delete.vertices(g, names(degree(g)[degree(g) == 0]))
  names(degree(g)[degree(g) == 0])
  E(g)$correlation <- E(g)$weight
  E(g)$weight <- abs(E(g)$weight)
  taxonomy <- read.csv('metadataBF.CSV', row.name = 1, check.names = FALSE)
  taxonomy <- taxonomy[as.character(V(g)$name),]#将所有g中有的otu的信息提取出来
  V(g)$Kingdom <- taxonomy$Kingdom
  V(g)$Phylum <- taxonomy$Phylum
  V(g)$Class <- taxonomy$Class
  V(g)$Order <- taxonomy$Order
  V(g)$Family <- taxonomy$Family
  V(g)$Genus <- taxonomy$Genus
  V(g)$Species <- taxonomy$Species
  edge <- data.frame(as_edgelist(g))
  df <- as.data.frame(E(g)$correlation)
  df[df>0] <- 1
  df[df<0] <- -1
  colnames(df) <- c('cor')
  edge_list <- data.frame(
    source = edge[[1]],
    target = edge[[2]],
    weight = E(g)$weight,
    correlation = E(g)$correlation,
    cor = df )
  head(edge_list)
  write.table(edge_list, 'R_edge_screen0.0001_r0.8p0.05.csv', sep = ',', row.names = FALSE, quote = FALSE)##写出边列表
  node <- data.frame(
    id = names(V(g)),
    kingdom =V(g)$Kingdom,
    phylum =V(g)$Phylum,
    class =V(g)$Class,
    order =V(g)$Order,
    family =V(g)$Family,
    genus =V(g)$Genus,
    species =V(g)$Species )
  write.table(node, 'R_node_screen0.0001_r0.8p0.05.csv', sep = ',', row.names = FALSE, quote = FALSE)
  -----------------------------------------------
  # network property
  #  The size of the graph (number of edges)
  num.edges = length(E(g)) # length(curve_multiple(igraph))
  num.edges
  #  Order (number of vertices) of a graph
  num.vertices = length(V(g))# length(diversity(igraph, weights = NULL, vids = V(igraph)))
  num.vertices
  # connectance = edge_density(g,loops=FALSE)
  # Average degree
  average.degree = mean(igraph::degree(g))
  # Average path length
  average.path.length = average.path.length(g) 
  # Diameter
  diameter = diameter(g, directed = FALSE, unconnected = TRUE, weights = NULL)
  #  edge connectivity / group adhesion
  edge.connectivity = edge_connectivity(g)
  edge.connectivity
  # Clustering coefficient
  clustering.coefficient = transitivity(g) 
  clustering.coefficient
  no.clusters = no.clusters(g)
  no.clusters
  # Betweenness centralization
  centralization.betweenness = centralization.betweenness(g)$centralization 
  centralization.betweenness
  # Degree centralization
  centralization.degree = centralization.degree(g)$centralization
  centralization.degree
  network_property <-c(num.edges=num.edges,num.vertices=num.vertices,connectance=connectance,
                       average.degree=average.degree,average.path.length=average.path.length,
                       diameter=diameter,edge.connectivity=edge.connectivity,clustering.coefficient=clustering.coefficient,
                       no.clusters=no.clusters,centralization.betweenness=centralization.betweenness,
                       centralization.degree=centralization.degree)
  network_property <- data.frame(network_property)
  write.csv(network_property, 'R_network_property.csv', row.names = T)

##robustness
 library(igraph)
  library(ggplot2)
  #install.packages("rsq")
  library(rsq)
  setwd("D:\")
  record <- c()
  record <- cbind(record,"D")
  result<-c()
  a=read.csv("D_edge_screen0.0001_r0.8p0.05.csv",header = TRUE) 
  a$source=as.factor(a$source)
  a$target=as.factor(a$target)
  b=a[,c(1:2)]
  b=t(b)
  b=t(b)
  ig=graph_from_edgelist(b,directed=FALSE)
  natcon <- function(ig) {
    N   <- vcount(ig)
    adj <- get.adjacency(ig)
    evals <- eigen(adj)$value
    nc  <- log(mean(exp(evals)))
    nc / (N - log(N))
  }
  nc.attack <- function(ig) {
    hubord <- order(rank(betweenness(ig)), rank(degree(ig)), decreasing=TRUE)
    sapply(1:round(vcount(ig)*.8), function(i) {
      ind <- hubord[1:i]
      tmp <- delete_vertices(ig, V(ig)$name[ind])
      natcon(tmp)
    }) }
  nc<- nc.attack(ig)
  nc
  write.csv(nc,"D-nc.csv")
  p <- read.csv("D-nc.csv")
  colnames(p)[2] <-"NC"
  p$RM <- p$X/vcount(ig)
  ncmod <- glm(NC~RM,data = p)
  summary(ncmod)
  record <- cbind(record,ncmod$coefficients[2])
  record <- cbind(record,rsq(ncmod))
  p5 <- p4+
    geom_abline(slope = ncmod$coefficients[2], intercept = ncmod$coefficients[1], 
                color = "#8DD3C7", linewidth = 2, alpha = 1)+
    geom_point(data = p, mapping = aes(x = RM, y = NC), color = "#8DD3C7",alpha = 1) +
    ylim (0, 0.06) +
    theme(panel.background = element_rect(fill = "transparent", colour = "black"))+ 
    theme(axis.text.y  = element_text(size = 20,color="black"))+
    theme(axis.title.y = element_text(size = 20, color="black"))+
    theme(axis.title.x = element_text(size = 20, color="black"))+
    theme(legend.text=element_text(size=20, color="black"))+#图例字体大小
    theme(axis.text.x = element_text(size = 20,color="black")) 
  p4 <- p3+
    geom_abline(slope = ncmod$coefficients[2], intercept = ncmod$coefficients[1], 
                color = "#FFCC00", linewidth = 2, alpha = 1)+
    geom_point(data = p, mapping = aes(x = RM, y = NC), color = "#FFCC00",alpha = 1) +
    ylim (0, 0.06) +
    theme(panel.background = element_rect(fill = "transparent", colour = "black"))+
    theme(axis.text.y  = element_text(size = 20,color="black"))+
    theme(axis.title.y = element_text(size = 20, color="black"))+
    theme(axis.title.x = element_text(size = 20, color="black"))+
    theme(legend.text=element_text(size=20, color="black"))+
    theme(axis.text.x = element_text(size = 20,color="black")) 
  p3 <- p2+ 
    geom_abline(slope = ncmod$coefficients[2], intercept = ncmod$coefficients[1], 
                color = "#BEBADA", linewidth = 2, alpha = 1)+
    geom_point(data = p, mapping = aes(x = RM, y = NC), color = "#BEBADA",alpha = 1) +
    ylim (0, 0.06) +
    theme(panel.background = element_rect(fill = "transparent", colour = "black"))+
    theme(axis.text.y  = element_text(size = 20,color="black"))+
    theme(axis.title.y = element_text(size = 20, color="black"))+
    theme(axis.title.x = element_text(size = 20, color="black"))+
    theme(legend.text=element_text(size=20, color="black"))+
    theme(axis.text.x = element_text(size = 20,color="black")) 
  p1 <- ggplot() + 
    geom_abline(slope = ncmod$coefficients[2], intercept = ncmod$coefficients[1], 
                color = "#80B1D3", linewidth = 2, alpha = 1)+
    geom_point(data = p, mapping = aes(x = RM, y = NC), color = "#80B1D3",alpha = 1) +
    theme_bw()
  p1
  write.csv(result,file='D_slope&r2.csv')
  result<-rbind(result,record)
  record <- c()
  record <- cbind(record,"D")
  a=read.csv("D_edge_screen0.0001_r0.8p0.05.csv",header = TRUE) 
  a$source=as.factor(a$source)
  a$target=as.factor(a$target)
  b=a[,c(1:2)]
  b=t(b)
  b=t(b)
  ig=graph_from_edgelist(b,directed=FALSE)
  natcon <- function(ig) {
    N   <- vcount(ig)
    adj <- get.adjacency(ig)
    evals <- eigen(adj)$value
    nc  <- log(mean(exp(evals)))
    nc / (N - log(N))
  }
  nc.attack <- function(ig) {
    hubord <- order(rank(betweenness(ig)), rank(degree(ig)), decreasing=TRUE)
    sapply(1:round(vcount(ig)*.8), function(i) {
      ind <- hubord[1:i]
      tmp <- delete_vertices(ig, V(ig)$name[ind])
      natcon(tmp)
    }) }
  nc<- nc.attack(ig)
  nc
  write.csv(nc,"DNase-nc.csv")
  p <- read.csv("DNase-nc.csv")
  colnames(p)[2] <-"NC"
  p$RM <- p$X/vcount(ig)
  ncmod <- glm(NC~RM,data = p)
  summary(ncmod)
  record <- cbind(record,ncmod$coefficients[2])
  record <- cbind(record,rsq(ncmod))
  p2 <- p1 + 
    geom_abline(slope = ncmod$coefficients[2], intercept = ncmod$coefficients[1], 
                color = "#FB8072", linewidth = 2, alpha = 1)+
    geom_point(data = p, mapping = aes(x = RM, y = NC), color = "#FB8072",alpha = 1) +
    ylim (0, 0.06) +
    theme(panel.background = element_rect(fill = "transparent", colour = "black"))+ 
    theme(axis.text.y  = element_text(size = 20,color="black"))+
    theme(axis.title.y = element_text(size = 20, color="black"))+
    theme(axis.title.x = element_text(size = 20, color="black"))+
    theme(legend.text=element_text(size=20, color="black"))+
    theme(axis.text.x = element_text(size = 20,color="black"))
  p2
  result<-rbind(result,record)
  record <- c()
  record <- cbind(record,"D")
  p2
  ggsave("XXX.pdf",p5,  width = 8, height = 5)
  result
  write.csv(result,file='S_slope&r2.csv')
  p <- p5+theme(panel.grid = element_blank())
  p
  p5 <- p4 + 
    geom_abline(slope = ncmod$coefficients[2], intercept = ncmod$coefficients[1], 
                color = "#BEBADA", linewidth = 2, alpha = 1)+
    geom_point(data = p, mapping = aes(x = RM, y = NC), color = "#BEBADA",alpha = 1) 


##Figure4
#distance-dacy
setwd("D:/")
  site <- read.delim('Rsite.txt', sep = '\t', row.names = 1, check.names = FALSE)
  site_dis <- geosphere::distm(site[c('longitude', 'laititude')]) 
  rownames(site_dis) <- rownames(site)
  colnames(site_dis) <- rownames(site)
  site_dis <- reshape2::melt(site_dis)
  site_dis <- subset(site_dis, value != 0)
  head(site_dis)
  spe <- read.delim('OTU_rare.txt', sep = '\t', row.names = 1, check.names = FALSE)
  spe <- data.frame(t(spe))
  comm_sim <- 1 - as.matrix(vegan::vegdist(spe, method = 'bray'))
  diag(comm_sim) <- 0 
  comm_sim[upper.tri(comm_sim)] <- 0  
  comm_sim <- reshape2::melt(comm_sim)
  comm_sim <- subset(comm_sim, value != 0)
  head(comm_sim)
  comm_dis <- merge(comm_sim, site_dis, by = c('Var1', 'Var2'))
  names(comm_dis) <- c('site1', 'site2', 'comm_sim', 'site_dis')
  head(comm_dis)
  write.table(comm_sim, 'BC similarity.txt', sep = '\t', row.names = FALSE, quote = FALSE)
  write.table(comm_dis, 'Rsimilarity.txt', sep = '\t', row.names = FALSE, quote = FALSE)

  data <- read.csv('Tsimilarity.csv',header = T)
  install.packages("ggplot2")
  library(geosphere)
  library(ggpubr)
  library(ggplot2)
  library(ggpmisc)
  install
  site_dis <- geosphere::distm(sample[c('longitude', 'laititude')])
  data$group <- factor(data$group,levels = c("T","D","S","P","R"))
  scale_color_manual(values = c("#0073c2","#fa8072","#D5544D","#7aa6dc","#efc000","#ffff00","#27ae60","#317e00"))
  p1 <- ggplot(data, aes( x = site_dis/1000, y =  comm_sim, color = group)) +
    geom_point( aes( color = group),size=1.5,alpha=0.5)+ 
    scale_color_manual(values = c("#80B1D3","#FB8072" ,"#BEBADA","#FFCC00","#8DD3C7"))+
    labs(x="Distance (km)",y="Bray-Curtis Similarity")+
    geom_smooth(method = 'lm', formula = y ~ x, se = F,size=1.5) +
    stat_poly_eq(aes(label=paste(..rr.label..,..p.value.label..,sep = "~~~~")),formula = y~x,parse=T,size=2.5)+
    theme_bw()+theme(panel.grid.major= element_blank())
  p2 <- p1+labs(color = "Treat")
  p2
  library(dplyr)
  install.packages("ggpmisc")
  library(ggpmisc)
  library(ggpubr)
  library(gridExtra)
  data <- read.csv('Tsimilarity.csv',  row.names = 1, check.names = FALSE)
  fit <- lm(comm_sim~site_dis, data = comm_dis) 
##iCAPM
m(list=ls())
  t0=Sys.time() # to calculate time cost
  # 3 # load R packages and data
  library(iCAMP)
  library(ape)
  # 1 # set folder paths and file names, please change according to the folder paths and file names in your computer.
  # the folder saving the input files
  wd="F:/R"
  # the OTU table file (Tab delimited txt file)
  comm<-t(read.csv("otutab_16S_rarefy_ck.csv",header=T,row.names=1,check.names = F))
  # the phylogenetic tree file
  tree<-read.tree("root_tree.nwk")
  # the environmental varialbes
  env<-read.csv("ENV_soilck.csv", header=TRUE, row.names=1)
  # if you do not have env file or the env may not represent niche, skip step 7 and 8, but check the alternative way to determine binning setting, e.g. bin.size.limit.
  # the folder to save the output. please change to a new folder even if you are just testing the example data.
  save.wd="F:/R"
  if(!dir.exists(save.wd)){dir.create(save.wd)}
  # 2 # key parameter setting
  prefix="Test"  # prefix of the output file names. usually use a project ID.
  rand.time=100  # randomization time, 1000 is usually enough. For example test, you may set as 100 or less to save time.
  nworker=8 # nworker is thread number for parallel computing, which depends on the CPU core number of your computer.
  memory.G=11 # to set the memory size as you need (but should be less than the available space in your hard disk), so that calculation of large tree will not be limited by physical memory. unit is Gb.
  setwd(wd)
  # 4 # match sample IDs in OTU table and treatment information table
  sampid.check=match.name(rn.list=list(comm=comm,env=env)) 
  comm=sampid.check$comm
  comm=comm[,colSums(comm)>0,drop=FALSE] 
  env=sampid.check$env 
  # 5 # match OTU IDs in OTU table and tree file
  spid.check=match.name(cn.list=list(comm=comm),tree.list=list(tree=tree))
  comm=spid.check$comm
  tree=spid.check$tree
  # 6 # calculate pairwise phylogenetic distance matrix.
  setwd(save.wd)
  if(!file.exists("pd.desc")) 
  {
    pd.big=iCAMP::pdist.big(tree = tree, wd=save.wd, nworker = nworker, memory.G = memory.G)
  }else{
    # if you already calculated the phylogenetic distance matrix in a previous run
    pd.big=list()
    pd.big$tip.label=read.csv(paste0(save.wd,"/pd.taxon.name.csv"),row.names = 1,stringsAsFactors = FALSE)[,1]
    pd.big$pd.wd=save.wd
    pd.big$pd.file="pd.desc"
    pd.big$pd.name.file="pd.taxon.name.csv"
  }
  # 7 # assess niche preference difference between species
  # env is required for this step.
  setwd(save.wd)
  niche.dif=iCAMP::dniche(env = env,comm = comm,method = "niche.value",
                          nworker = nworker,out.dist=FALSE,bigmemo=TRUE,
                          nd.wd=save.wd)
  # 8 # within-bin phylogenetic signal assessment.
  # For real data, you may try several different settings of binning, and choose the one leading to the best within-bin phylogenetic signal.
  # env is required for this step.
  # 8.1 # try phylogenetic binning using current setttings.
  ds = 0.2 # setting can be changed to explore the best choice
  bin.size.limit = 24 # setting can be changed to explore the best choice. # here set as 5 just for the small example dataset. For real data, usually try 12 to 48.
  phylobin=taxa.binphy.big(tree = tree, pd.desc = pd.big$pd.file,pd.spname = pd.big$tip.label,
                           pd.wd = pd.big$pd.wd, ds = ds, bin.size.limit = bin.size.limit,
                           nworker = nworker)
  # 8.2 # test within-bin phylogenetic signal.
  sp.bin=phylobin$sp.bin[,3,drop=FALSE]
  sp.ra=colMeans(comm/rowSums(comm))
  abcut=3 # you may remove some species, if they are too rare to perform reliable correlation test.
  commc=comm[,colSums(comm)>=abcut,drop=FALSE]
  dim(commc)
  spname.use=colnames(commc)
  binps=iCAMP::ps.bin(sp.bin = sp.bin,sp.ra = sp.ra,spname.use = spname.use,
                      pd.desc = pd.big$pd.file, pd.spname = pd.big$tip.label, pd.wd = pd.big$pd.wd,
                      nd.list = niche.dif$nd,nd.spname = niche.dif$names,ndbig.wd = niche.dif$nd.wd,
                      cor.method = "pearson",r.cut = 0.1, p.cut = 0.05, min.spn = 5)
  if(file.exists(paste0(prefix,".PhyloSignalSummary.csv"))){appendy=TRUE;col.namesy=FALSE}else{appendy=FALSE;col.namesy=TRUE}
  write.table(data.frame(ds=ds,n.min=bin.size.limit,binps$Index),file = paste0(prefix,".PhyloSignalSummary.csv"),
              append = appendy, quote=FALSE, sep=",", row.names = FALSE,col.names = col.namesy)
  if(file.exists(paste0(prefix,".PhyloSignalDetail.csv"))){appendy2=TRUE;col.namesy2=FALSE}else{appendy2=FALSE;col.namesy2=TRUE}
  write.table(data.frame(ds=ds,n.min=bin.size.limit,binID=rownames(binps$detail),binps$detail),file = paste0(prefix,".PhyloSignalDetail.csv"),
              append = appendy2, quote = FALSE, sep = ",", row.names = FALSE, col.names = col.namesy2)
  # 9 # iCAMP analysis
  bin.size.limit = 24
  sig.index="Confidence" # see other options in help document of icamp.big.
  icres=iCAMP::icamp.big(comm=comm, pd.desc = pd.big$pd.file, pd.spname=pd.big$tip.label,
                         pd.wd = pd.big$pd.wd, rand = rand.time, tree=tree,
                         prefix = prefix, ds = 0.2, pd.cut = NA, sp.check = TRUE,
                         phylo.rand.scale = "within.bin", taxa.rand.scale = "across.all",
                         phylo.metric = "bMPD", sig.index=sig.index, bin.size.limit = bin.size.limit, 
                         nworker = nworker, memory.G = memory.G, rtree.save = FALSE, detail.save = TRUE, 
                         qp.save = FALSE, detail.null = FALSE, ignore.zero = TRUE, output.wd = save.wd, 
                         correct.special = TRUE, unit.sum = rowSums(comm), special.method = "depend",
                         ses.cut = 1.96, rc.cut = 0.95, conf.cut=0.975, omit.option = "no",meta.ab = NULL)
  setwd("F:/R")
  treat<-read.csv("treat_A.csv",header=T,row.names=1)
  # 10 # iCAMP bin level statistics
  icbin=icamp.bins(icamp.detail = icres$detail, treat = treat,silent=FALSE, boot = TRUE,
                   rand.time = rand.time,between.group = FALSE)
  save(icbin,file = paste0(prefix,".iCAMP.Summary.rda")) # just to archive the result. rda file is automatically compressed, and easy to load into R.
  write.csv(icbin$Pt,file = paste0(prefix,".ProcessImportance_EachGroup.csv"),row.names = FALSE)
  write.csv(icbin$Ptk,file = paste0(prefix,".ProcessImportance_EachBin_EachGroup.csv"),row.names = FALSE)
  write.csv(icbin$Ptuv,file = paste0(prefix,".ProcessImportance_EachTurnover.csv"),row.names = FALSE)
  write.csv(icbin$BPtk,file = paste0(prefix,".BinContributeToProcess_EachGroup.csv"),row.names = FALSE)
  
  write.csv(data.frame(ID=rownames(icbin$Class.Bin),icbin$Class.Bin,stringsAsFactors = FALSE),
            file = paste0(prefix,".Taxon_Bin.csv"),row.names = FALSE)
  write.csv(icbin$Bin.TopClass,file = paste0(prefix,".Bin_TopTaxon.csv"),row.names = FALSE)
  
  # cate<-clas
  # 
  # # 3 # summarize each category
  # icampcate=icamp.cate(icamp.bins.result = icbin, comm = comm, cate = cate,
  #                      treat = treat, silent = FALSE, between.group = FALSE)
  # 
  # write.csv(icampcate$Ptuvx,file = "16sRecahpairsample.csv",row.names = FALSE)
  # write.csv(icampcate$Ptx,file = "16sRamongsample.csv",row.names = FALSE)
##MST
setwd("E:/DY/MST/Total")
library(NST)
comm_S<-read.csv("OTU_rare.csv",header=T,row.names=1)
group_S <-read.csv("group.csv", header=F,row.names = 1)
comm_S<-t(comm_S)
set.seed(123)
tnst <- tNST(comm = comm_S, group = group_S, dist.method = 'jaccard', null.model = 'PF', 
             rand = 1000, nworker = 50)
names(tnst)
tnst$index.pair
tnst$index.grp
nst_group <- tnst$index.pair.grp
nst_group
write.csv(nst_group,'nst.csv')
setwd("D:/")
install.packages("Hmisc")
library(Hmisc)
library(ggplot2)
library(ggpubr)
data = read.csv("nst.csv", header=T)
group = read.csv("group.csv", header=F,row.names = 1)
col=c("#80b1d3","#fb8072","#BEBADA", "#FFCC00","#8DD3C7")
col=c("#fb8072","#FFFFB3","#8DD3C7", "#BEBADA","#80b1d3")
my_comparisons <- list(c("T", "D"),  c("T", "R"),
                       c("D", "S"), c("D", "P"), c("D", "R"), c("S", "P")
                       , c("S", "R"), c("P", "R"))
p = ggplot(data,aes(fill = group,x=factor(group,level=c("T","D","S","P","R")), y=MST.ij.ruzicka))+
  geom_violin(position = position_dodge(width = 0.1), scale = 'width')+  
  geom_violin(position = position_dodge(width = 0.1), scale = 'width')+  
  geom_boxplot(alpha=1,outlier.size=0, size=0.3, width=0.3,fill="white")+
  scale_fill_manual(values = col)+
  labs(x="Treat", y="Modified Stochasticity Ratio(MST)", color=group)+
  scale_x_discrete(limits=c("T","D","S","P","R")+
  ylim(0, 1))
mytheme = theme_classic() + theme(axis.text.x = element_text(size = 12),axis.text.y = element_text(size = 12))+
  theme(axis.title.y= element_text(size=15))+theme(axis.title.x = element_text(size = 15))+
  theme(legend.title=element_text(size=10),legend.text=element_text(size=10))
p2=p+mytheme
p2 
ggsave("MST_box.pdf", p4, width = 150, height = 180,units = "mm")
p4 = ggplot(data,aes(group,x=factor(group,level=c("T","D","S","P","R")), y=MST.ij.ruzicka))+###abundance： y=species
  stat_boxplot(geom="errorbar",width=0.15)+
  scale_fill_manual(values = col)+
  geom_boxplot(alpha=0.7,aes(fill=group))+
  #geom_line(aes(group=group) ,colour="#9C9C9C",lwd=0.2)+
  #geom_point(size = 0.5)+
  scale_y_continuous(name="Modified Stochasticity Ratio(MST)")+
  scale_x_discrete(name="Treat")+
  theme_bw()+
  theme(legend.position='none')+
  theme(panel.background = element_rect(fill = "white", colour = "black"),
        panel.grid = element_blank(),
        panel.border = element_blank(),
        text = element_text(colour="black",size=12),
        axis.title = element_text(colour="black",face="bold"),
        axis.text=element_text(colour="black",size=12),
        axis.title.x = element_blank(),
        axis.title.y = element_text(colour="black", size = 12))+
  xlab("Treat")+ylab("Modified Stochasticity Ratio(MST) ")+coord_cartesian(ylim = c(0,1))
##MST
library(Hmisc)
library(minpack.lm)
library(stats4)
setwd("~/Documents")
  spp<-read.csv("OTU_MB.csv",header = T, stringsAsFactors=F,row.names = 1)
  spp<-t(spp)
N <- mean(apply(spp, 1, sum))
p.m <- apply(spp, 2, mean)
p.m <- p.m[p.m != 0]
p <- p.m/N
spp.bi <- 1*(spp>0)
freq <- apply(spp.bi, 2, mean)
freq <- freq[freq != 0]
C <- merge(p, freq, by=0)
C <- C[order(C[,2]),]
C <- as.data.frame(C)
C.0 <- C[!(apply(C, 1, function(y) any(y == 0))),]
p <- C.0[,2]
freq <- C.0[,3]
names(p) <- C.0[,1]
names(freq) <- C.0[,1]
d = 1/N
m.fit <- nlsLM(freq ~ pbeta(d, N*m*p, N*m*(1 -p), lower.tail=FALSE),start=list(m=0.1))
m.fit 
m.ci <- confint(m.fit, 'm', level=0.95)
freq.pred <- pbeta(d, N*coef(m.fit)*p, N*coef(m.fit)*(1 -p), lower.tail=FALSE)
pred.ci <- binconf(freq.pred*nrow(spp), nrow(spp), alpha=0.05, method="wilson", return.df=TRUE)
Rsqr <- 1 - (sum((freq - freq.pred)^2))/(sum((freq - mean(freq))^2))
Rsqr 
write.csv(p, file = "p.csv")
write.csv(freq, file = "freq.csv")
write.csv(freq.pred, file = "freq.pred.csv")
bacnlsALL <-data.frame(p,freq,freq.pred,pred.ci[,2:3])
inter.col<-rep('#bfbfbf',nrow(bacnlsALL))
inter.col[bacnlsALL$freq <= bacnlsALL$Lower]<-'#decbe4'
inter.col[bacnlsALL$freq >= bacnlsALL$Upper]<-'#fcb4ae'
library(grid)
grid.newpage()
pushViewport(viewport(h=0.6,w=0.6))
pushViewport(dataViewport(xData=range(log10(bacnlsALL$p)), yData=c(0,1.02),extension=c(0.02,0)))
grid.rect()
grid.points(log10(bacnlsALL$p), bacnlsALL$freq,pch=20,gp=gpar(col=inter.col,cex=0.7))
grid.yaxis()
grid.xaxis()
grid.lines(log10(bacnlsALL$p),bacnlsALL$freq.pred,gp=gpar(col='#ffd9a6',lwd=2),default='native')
grid.lines(log10(bacnlsALL$p),bacnlsALL$Lower ,gp=gpar(col='#ffd9a6',lwd=2,lty=2),default='native') 
grid.lines(log10(bacnlsALL$p),bacnlsALL$Upper,gp=gpar(col='#ffd9a6',lwd=2,lty=2),default='native') 
grid.text(y=unit(0,'npc')-unit(2.5,'lines'),label='Mean Relative Abundance (log10)', gp=gpar(fontface=2)) 
grid.text(x=unit(0,'npc')-unit(3,'lines'),label='Frequency of Occurance',gp=gpar(fontface=2),rot=90) 
#grid.text(x=unit(0,'npc')-unit(-1,'lines'), y=unit(0,'npc')-unit(-15,'lines'),label='Mean Relative Abundance (log)', gp=gpar(fontface=2)) 
#grid.text(round(coef(m.fit)*N),x=unit(0,'npc')-unit(-5,'lines'), y=unit(0,'npc')-unit(-15,'lines'),gp=gpar(fontface=2)) 
#grid.text(label = "Nm=",x=unit(0,'npc')-unit(-3,'lines'), y=unit(0,'npc')-unit(-15,'lines'),gp=gpar(fontface=2))
#grid.text(round(Rsqr,2),x=unit(0,'npc')-unit(-5,'lines'), y=unit(0,'npc')-unit(-16,'lines'),gp=gpar(fontface=2))
#grid.text(label = "Rsqr=",x=unit(0,'npc')-unit(-3,'lines'), y=unit(0,'npc')-unit(-16,'lines'),gp=gpar(fontface=2))
draw.text <- function(just, i, j) {
  grid.text(paste("Rsqr=",round(Rsqr,3),"\n","Nm=",round(coef(m.fit)*N)), x=x[j], y=y[i], just=just)
  #grid.text(deparse(substitute(just)), x=x[j], y=y[i] + unit(2, "lines"),
  #          gp=gpar(col="grey", fontsize=8))
}
x <- unit(1:4/5, "npc")
y <- unit(1:4/5, "npc")
draw.text(c("centre", "bottom"), 4, 1)

##Figure5
##relative abundance
library(reshape2)
library(ggplot2)
setwd('D:/')
phylum_top15 <- read.csv('3w5_genus_deleteR.csv', row.names = 1, stringsAsFactors = FALSE, check.names = FALSE)
phylum_top15$Taxonomy <- factor(rownames(phylum_top15), levels = rev(rownames(phylum_top15)))
phylum_top15 <- melt(phylum_top15, id = 'Taxonomy')
group <- read.csv('XXX.csv', row.names = 1, stringsAsFactors = FALSE, check.names = FALSE)
names(group)[1] <- 'variable'
phylum_top15 <- merge(phylum_top15, group, by = 'variable')
x = paste0('site',1:7)
phylum_top15$group = factor(phylum_top15$group,levels = x)
#write.csv(phylum_top15, file = " phylum_top15.csv")
#phylum_top15 <- read.csv(' phylum_top15.csv', row.names = 1, stringsAsFactors = FALSE, check.names = FALSE)
p <- ggplot(phylum_top15, aes(variable, 100 * value, fill = Taxonomy)) +
  geom_col(position = 'stack', width = 0.6) +
  facet_wrap(~group, scales = 'free_x', nrow = 2)+  # Arrange in 2 rows for vertical layout +
  scale_fill_manual(values =  rev(c(   '#CCEBC5','#80B1D3', '#FDB462', '#B3DE69', '#FCCDE5','#8DD3C7', '#FFFFB3', '#BEBADA', '#FB8072' ))) +
  theme_bw() +theme(panel.grid.major =element_blank(), panel.grid.minor = element_blank(),panel.background = element_blank(),axis.line = element_line(colour = "black"))+
  theme(strip.background = element_rect( size=0.5))+
  theme(strip.text.x = element_text(size = 10, colour = "black")) + 
  theme(axis.text = element_blank())+
  #theme(axis.text.x = element_text(color="black",size = 10,face = "plain"))+
  theme(axis.text.y = element_text(color="black",size = 10,face = "plain"))+
  xlab("") + theme(axis.title.x = element_text(size = 8, face = "plain"))+
  ylab("Relative abundance(%)") + theme(axis.title.y = element_text(size = 15, face = "plain"))+
  theme(legend.text=element_text(size=12, face = "plain"))+
  theme(legend.position="right")+
  guides(fill=guide_legend(title=NULL))+
  theme(panel.grid = element_blank(), panel.background = element_rect(color = 'black', fill = 'transparent'), strip.text = element_text(size = 8))+ 
  theme(panel.border = element_rect(color="black", size=0.1))+
  theme(axis.ticks.x=element_line(color="black",size=0.3,lineend = 1))+
  theme(axis.ticks.y=element_line(color="black",size=0.3,lineend = 1))
#guides(fill=FALSE)
p
ggsave('XXXpdf', p, width = 8, height = 5)

##PCoA
setwd("D:")
library(vegan)
library(ggplot2)
otu <- read.csv(file="otu_5_NM.csv",header=TRUE, row.names=1)
head(otu)
otu <- t(otu)
head(otu)
otu.distance <- vegdist(otu, method = 'bray')
otu.distance
pcoa <- cmdscale (otu.distance,eig=TRUE)
pc12 <- pcoa$points[,1:2]
pc <- round(pcoa$eig/sum(pcoa$eig)*100,digits=2)
pc12 <- as.data.frame(pc12)
pc12$samples <- row.names(pc12)
head(pc12)
p <- ggplot(pc12,aes(x=V1, y=V2))+
  geom_point(size=3)+theme_bw()
p
group <- read.csv("PCoA_group_NM.csv", header=TRUE)
df <- merge(pc12,group,by="samples")
#write.csv(df,file = "df.csv",row.names = TRUE)
set.seed(2)
adonis_result<-adonis2(otu ~ group, data = group,permutations = 999,method="bray")
adonis_result
color <- c('#80B1D3','#FB8072','#BEBADA','#FFCC00','#8DD3C7')
color <- c('#FB8072','#FFCC00','#8DD3C7','#BEBADA','#80B1D3')
color=c('#FB8072','#80B1D3')#TD
color=c('#FFCC00','#80B1D3')#TP
color=c('#BEBADA','#80B1D3')#TS
color=c('#8DD3C7','#80B1D3')#TR
color=c('#FFC0CB','#80B1D3')#TM
color=c('#FFC0CB','#FFCC00')#MP
dune_adonis <- paste0("adonis R2: ",round(adonis_result$R2,4), "; P-value: ", adonis_result$`Pr(>F)`)
p<-ggplot(data=df,aes(x=V1,y=V2,
                      color=group))+
  theme_bw()+
  geom_point(size=4)+
  theme(panel.grid = element_blank())+
  geom_vline(xintercept = 0,lty="dashed")+
  geom_hline(yintercept = 0,lty="dashed")+
  geom_text(aes(label=samples, y=V2+0.03,x=V1+0.03, vjust=0),size=0)+
  #guides(color=guide_legend(title=NULL))+
  labs(x=paste0("PCoA1 ","(",pc[1],"%)"),
       y=paste0("PCoA2 ","(",pc[2],"%)"),
       title=dune_adonis)+
  scale_color_manual(values = color) +
  scale_fill_manual(values = color)+
  theme(axis.title.x=element_text(size=12),
        axis.title.y=element_text(size=12,angle=90),
        axis.text.y=element_text(size=12),
        axis.text.x=element_text(size=12),
        panel.grid=element_blank()) + 
  stat_ellipse(data=df,geom = "polygon",level=0.95,linetype = 2, linewidth=0.2,aes(fill=group),alpha=0.2,show.legend = FALSE)
p
ggsave(p,filename = "PCoA_MP.pdf",width = 5, height = 5)
ggsave(p,filename = "PCoA_5个otu_NM.pdf",width = 6, height = 5)

##Similarity
setwd("D:/")
spe <- read.csv('otu.csv',  row.names = 1, check.names = FALSE)
spe <- data.frame(t(spe))
comm_sim <- 1 - as.matrix(vegan::vegdist(spe, method = 'bray'))
diag(comm_sim) <- 0 
comm_sim[upper.tri(comm_sim)] <- 0  
comm_sim <- reshape2::melt(comm_sim)
comm_sim <- subset(comm_sim, value != 0)
write.csv(comm_sim, 'similarity.csv',  row.names = FALSE, quote = FALSE)
setwd("D:/")
species<-read.csv("BC similarity.csv",header=T)
species$type<-as.factor(species$type)
species$ID<-as.factor(species$ID)
shapiro <- tapply(species$value, species$type, shapiro.test)
shapiro
bartlett.test(value ~ type, data=species)
library(rstatix)
res.aov<-anova_test(data = species, dv = value,   wid= ID, within =  type)
get_anova_table(res.aov)
scaleFUN<-  function(x) sprintf ("%.1f",x)
#colnames(species)<-c("Row.names","species","type")
species$group<-c(1:6,1:6,1:6,1:6,1:6,1:6)
my_comparisons <- list(c("T", "D"), c("T", "S"),c("T", "P"), c("T", "R"),c("S", "D")
                       ,c("S", "P"),c("S", "R"),c("P", "R"),c("T", "M"),c("P", "D"))
p4 = ggplot(species,aes(fill = type,x=factor(type,level=c("S/T","D/T","P/T","R/T","M/T","P/M")), y=value))+###abundance： y=species
  stat_boxplot(geom="errorbar",width=0.15)+
  geom_boxplot(alpha=0.7,aes(fill=type))+
  #geom_line(aes(group=group) ,colour="#9C9C9C",lwd=0.2)+
  geom_point(size = 0.5)+
  scale_y_continuous(name="Bray-Curtis Similarity",labels=scaleFUN)+
  scale_x_discrete(name="Treat")+
  theme_bw()+
  theme(legend.position='none')+
  theme(panel.background = element_rect(fill = "white", colour = "black"), 
        panel.grid = element_blank(),
        panel.border = element_blank(),
        text = element_text(colour="black",size=12),
        axis.title = element_text(colour="black",face="bold"),
        axis.text=element_text(colour="black",size=12),
        axis.title.x = element_blank(),
        axis.title.y = element_text(colour="black", size = 12))+
  xlab("Treat")+ylab("Bray-Curtis similarity ")+coord_cartesian(ylim = c(0.2,1))
  #stat_compare_means(comparisons=my_comparisons,label ="p.signif",step_increase = 0.1,map_signif_level = T,test = wilcox.test,paired = TRUE) # Add pairwise 
  #stat_compare_means(label.y = 0.58,label.x = 3,size=5) # Add global p-value
p4<-p4+scale_fill_brewer(palette = "Set2") 
p4
ggsave('Total.pdf', p4, width = 6, height = 5)

##Figure6
The evaluation of soil live prokaryotic abundance and diversity analysis accuracy based on different methods
##Copies
library(vegan)
library(ggplot2)
library(ggpubr)
library(ggsci)
setwd("D:/")
species<-read.csv("ES_copies.csv",header=T,row.names = 1)
species$treat<-as.factor(species$treat)
species$ID<-as.factor(species$ID)
species$treat <- factor(species$treat,levels = c("T","D","S","P","R"))
shapiro <- tapply(species$copies, species$treat, shapiro.test)
shapiro
bartlett.test(copies ~ treat, data=species)
library(rstatix)
res.aov<-anova_test(data = species, dv = copies,   wid= ID, within =  treat)
get_anova_table(res.aov)
scaleFUN<-  function(x) sprintf ("%.1f",x)
#colnames(species)<-c("Row.names","species","type")
species$group<-c(1:8,1:8,1:8,1:8,1:8)
my_comparisons <- list(c("T", "D"), c("T", "P"), c("T", "R"), c("D", "S"), c("D", "R"),
                       c("P", "S"), c("P", "R"), c("S", "R"))
p4 = ggplot(species,aes(fill = treat,x=factor(treat,level=c("T","D","S","P","R")), y=copies))+###abundance： y=species
  stat_boxplot(geom="errorbar",width=0.15)+
  geom_boxplot(alpha=0.7,aes(fill=treat))+
  geom_line(aes(group=group) ,colour="#9C9C9C",lwd=0.2)+
  geom_point(size = 0.5)+
  scale_y_continuous(name="Prokaryotic Copies(lg)",labels=scaleFUN)+
  scale_x_discrete(name="Nucleic acid extraction method")+
  scale_fill_manual(values=c("#80B1D3","#FB8072" ,"#BEBADA","#FFFFB3","#8DD3C7"))+
  theme_bw()+
  theme(legend.position='none')+
  theme(panel.background = element_rect(fill = "white", colour = "black"), 
        panel.grid = element_blank(),
        panel.border = element_blank(),
        text = element_text(colour="black",size=14),
        axis.title = element_text(colour="black",face="bold"),
        axis.text=element_text(colour="black",size=14),
        axis.title.x = element_blank(),
        axis.title.y = element_text(colour="black", size = 14))+
  stat_compare_means(comparisons=my_comparisons,  label ="p.signif",method = "t.test")
p4
ggsave('Copies.pdf', p4, width = 5, height = 5)

##removal efficiency
library(ggplot2)
library(RColorBrewer)
library(ggsci)
library(ggpubr)
install.packages("ggbreak")
library(ggbreak)
setwd("C:/Users/biubiuyy/Desktop/test")
aa<-read.csv("test_otu.csv",row.names = 1)
df<-aa[21:220,1:3]
#df<- as.data.frame(scale(df))
Group<-data.frame(c(rep(c(4:8,4:8,4:8,4:8),10)),c(rep(c(1),50)))
colnames(Group)<-c("pH","Group")
df<-cbind(df,Group)
write.csv(df,file = "test.csv")
df <- read.csv("test_site2.csv",row.names = 1)
df$pH<-as.factor(df$pH)
df$Sample3<-"Box plot"
p1=ggplot(df, aes(x=pH, y=Sample2,color=pH))+
  stat_boxplot(geom="errorbar",position=position_dodge(width=0.2),width=0.3,size=1)+
  geom_boxplot(aes(),notch = F,size=0.7)+
  geom_jitter(size = 2.5,alpha = 0.6,width = 0.2)+ 
  theme_bw()+scale_color_npg()+scale_fill_npg()+
  theme(axis.text=element_text(colour='black',size=9))+
  labs(x="Metabolic", y="Growth", color = "pH",fill = "pH")+
  facet_grid( ~Sample3, drop=TRUE,scale="free", space="free_x")+
  theme(strip.background = element_rect(fill=c("white")))+
  theme(strip.text = element_text(size = 12,face = 'bold',colour = "gray2"))+
  theme(axis.text=element_text(colour='black',size=11))
p1
plot_data2<-df
mean_df<-aggregate(plot_data2[,1:2],by=list(plot_data2[,4]),FUN=mean)
rownames(mean_df)<-mean_df[,1]
sd_df<-aggregate(plot_data2[,1:2],by=list(plot_data2[,4]),FUN=sd)
rownames(sd_df)<-sd_df[,1]
sd_df<-sd_df[,-1]
se_df<-sd_df/sqrt(16) 
se<-as.data.frame(se_df)
plot_data1<-cbind(mean_df,se)
colnames(plot_data1)<-c("pH","Sample1","Sample2","se1","se2")
#barplot
df$Sample3<-"Bar plot"
#barplot
p2 <- ggplot(df, aes(x = pH, y = Sample2, color = pH)) +
  geom_bar(data = plot_data1, mapping = aes(x = pH, y = Sample2, fill = pH), size = 1.03, position = "dodge", stat = "identity", width = 0.7, color = "black") +
  scale_fill_manual(values = c("#FB8072", "#FFFFB3", "#BEBADA")) + 
  scale_color_manual(values = c("#FB8072", "#FFFFB3", "#BEBADA")) + 
  geom_errorbar(data = plot_data1, mapping = aes(x = pH, ymin = Sample2 - se2, ymax = Sample2 + se2), width = 0.3, size = 0.8, color = "black") +
  geom_jitter(size = 2.5, alpha = 0.6, width = 0.2) + 
  theme_bw() +
  theme(axis.text = element_text(colour = 'black', size = 9)) +
  labs(x = "Metabolic", y = "", color = "pH", fill = "pH") +
  theme(strip.background = element_rect(fill = c("white"))) +
  theme(strip.text = element_text(size = 12, face = 'bold', colour = "gray2")) +
  theme(axis.text = element_text(colour = 'black', size = 11)) +
  guides(color = FALSE, fill = FALSE) +
  coord_cartesian(ylim = c(75, 105))
#scale_y_break(c(5,75),scales=2,space=0,expand = c(0,0))+
p2
ggsave('site2.pdf', p2, width = 6, height = 5)
